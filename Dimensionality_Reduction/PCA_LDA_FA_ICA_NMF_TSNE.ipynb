{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c51497",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa64c6",
   "metadata": {},
   "source": [
    "A technique for reducing the dimensionality of data. It applies a linear transformation to the original data and transforms it into a new coordinate system. The first coordinate (the first principal component) assumes the maximum variance, the second coordinate assumes the second largest variance, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a465a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5983a4f",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a239730a",
   "metadata": {},
   "source": [
    "A supervised learning technique for dimensionality reduction. Its goal is to find a projection direction that makes the projection points of the same class data as close as possible and the projection points of different classes as far away as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada0be2",
   "metadata": {},
   "source": [
    "# Feature Agglomeration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b1cef",
   "metadata": {},
   "source": [
    "This method merges together features that are similar. It's a bit like hierarchical clustering but applied to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d670203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import FeatureAgglomeration\n",
    "\n",
    "agglo = FeatureAgglomeration(n_clusters=2)\n",
    "agglo.fit(X)\n",
    "X_reduced = agglo.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec80ab",
   "metadata": {},
   "source": [
    "# Independent Component Analysis (ICA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54144a23",
   "metadata": {},
   "source": [
    "ICA separates a multivariate signal into additive subcomponents that are maximally independent. It's often used for blind source separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034475e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "transformer = FastICA(n_components=7, random_state=0)\n",
    "X_transformed = transformer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23795b39",
   "metadata": {},
   "source": [
    "# Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7fcc08",
   "metadata": {},
   "source": [
    " NMF is a group of algorithms where a matrix V is factorized into (usually) two matrices W and H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "H = model. Components_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d114e6",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9cd5b0",
   "metadata": {},
   "source": [
    "A machine learning algorithm for unseen data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
